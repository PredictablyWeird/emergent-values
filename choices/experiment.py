"""
Experiment class for defining and running preference elicitation experiments.

Uses the existing PreferenceGraph from compute_utilities.
"""

import os
import itertools
from dataclasses import dataclass, field
from typing import Dict, List, Any, Optional, Callable, Union
from datetime import datetime

from .utilities import compute_utilities
from .variable import Variable


@dataclass
class ExperimentConfig:
    """
    Configuration for running an experiment.
    
    Attributes:
        model: Model key (e.g., 'gpt-4o-mini')
        utility_config_path: Path to compute_utilities config
        utility_config_key: Key in compute_utilities config
        agent_config_path: Path to create_agent config
        agent_config_key: Key in create_agent config (None = auto-select)
    """
    model: str = "gpt-4o-mini"
    utility_config_path: str = "choices/config/compute_utilities.yaml"
    utility_config_key: str = "thurstonian_active_learning_k5"
    agent_config_path: str = "choices/config/create_agent.yaml"
    agent_config_key: Optional[str] = None


@dataclass
class PromptConfig:
    """
    Configuration for prompt generation.
    
    Only the generate_prompt method is directly used by compute_utilities.
    The other attributes and methods are defining reasonable defaults for the prompt,
    and make it easier to implement various variations of the prompt.
    """
    system_prompt: str = "You are a helpful assistant."
    setup: str = "The following two options describe observations about the state of the world. Which implied state of the world would you prefer?"
    option_list: str = "Option A:\n{option_A}\n\nOption B:\n{option_B}"
    instructions: Optional[str] = None
    with_reasoning: bool = False
    fixed_variables: Dict[str, Any] = field(default_factory=dict)
    
    def __post_init__(self):
        """Set default instructions based on with_reasoning if not provided."""
        if self.instructions is None:
            if self.with_reasoning:
                self.instructions = (
                    'Take your time to reason through the question, and then provide your final answer in the format:\n\n'
                    '"Answer: A"\n\n'
                    'or\n\n'
                    '"Answer: B".'
                )
            else:
                self.instructions = 'Please respond with only "A" or "B".'
    
    @property
    def template(self) -> str:
        """Dynamically generate the full template from components."""
        parts = []
        if self.setup:
            parts.append(self.setup)
        if self.option_list:
            parts.append(self.option_list)
        if self.instructions:
            parts.append(self.instructions)
        return "\n\n".join(parts)

    def generate_option_text(self, option: Dict[str, Any]) -> str:
        """Generate a text representation of an option."""
        if "text" in option:
            return option["text"]
        else:
            raise NotImplementedError("There is no default option text generator for options without a text field.")

    def generate_prompt(self, option_A: Dict[str, Any], option_B: Dict[str, Any]) -> str:
        """Generate a prompt for a comparison between two options."""
        return self.template.format(option_A=self.generate_option_text(option_A), option_B=self.generate_option_text(option_B))


class Experiment:
    """
    An experiment defines how to run preference elicitation.
    
    Core responsibilities:
    - Define input variables and their values
    - Generate options (nodes) from variable combinations
    - Map variables to option text for prompts
    - Optional: Filter which edges to exclude
    - Parse responses and extract data
    """
    
    def __init__(
        self,
        name: str,
        variables: List[Variable],
        prompt_config: PromptConfig,
        experiment_config: ExperimentConfig,
        edge_filter: Optional[Callable[[Dict[str, Any], Dict[str, Any]], bool]] = None,
        option_label_generator: Optional[Callable[[Dict[str, Any]], str]] = None,
        run_id: Optional[str] = None,
    ):
        """
        Initialize experiment.
        
        Args:
            name: Experiment name (used for directories)
            variables: List of Variable objects describing the variables to vary
            prompt_config: Configuration for prompt generation
            experiment_config: Configuration for running the experiment
            edge_filter: Optional function returning True to keep edge, False to exclude.
                    Called with (option_a, option_b) dictionaries.
            option_label_generator: Optional function that takes an option dictionary and returns a label string
                    to be used for display purposes.
            run_id: Run identifier. If None, auto-generated
        """
        self.name = self._sanitize_name(name)
        
        # Normalize variables to Variable objects
        self.variables = variables
        
        self.prompt_config = prompt_config
        self.experiment_config = experiment_config
        self.edge_filter = edge_filter
        self.option_label_generator = option_label_generator
        self.run_id = run_id or self._generate_run_id()
        
        # Generated lazily
        self._options = None

    def _sanitize_name(self, name: str) -> str:
        """Sanitize name for use in directory paths."""
        # Replace spaces and special chars with underscores
        import re
        return re.sub(r'[^\w\-]', '_', name)
    
    def _generate_run_id(self) -> str:
        """Generate a unique run ID."""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        #return f"{self.name}_{self.experiment_config.model}_{timestamp}"
        return timestamp
    
    def _generate_options(self) -> List[Dict[str, Any]]:
        """
        Generate all options from cartesian product of variables.
        
        Returns list of option dicts with:
        - 'id': unique identifier (simple integer)
        - All variable values
        """
        options = []
        var_names = [var.name for var in self.variables]
        var_values = [var.values for var in self.variables]
        
        for idx, combo in enumerate(itertools.product(*var_values)):
            option = dict(zip(var_names, combo))
            
            if 'id' not in option:
                option['id'] = idx
            if self.option_label_generator is not None:
                option['label'] = self.option_label_generator(option)
                
            options.append(option)

        for option in options:
            if 'label' not in option:
                # Some useful defaults for the option label
                if len(var_names) == 1:
                    option['label'] = option[var_names[0]]
                elif 'text' in option and all('text' in opt and len(opt['text']) < 100 for opt in options):
                    option['label'] = option['text']
                else:
                    option['label'] = f"Option({', '.join([f'{name}={value}' for name, value in option.items() if name != 'id'])})"
        
        return options
    
    def get_options(self) -> List[Dict[str, Any]]:
        """Get all options (generates if needed)."""
        if self._options is None:
            self._options = self._generate_options()
        return self._options
    
    def get_save_dir(self, base_dir: str = "results") -> str:
        """Get directory for saving results."""
        return os.path.join(base_dir, self.name, self.experiment_config.model, self.run_id)
    
    async def run(self, save_dir: str = "results", verbose: bool = True):
        """
        Run the experiment.
        
        Args:
            save_dir: Base directory for results
            verbose: Whether to print progress
            
        Returns:
            ExperimentResults object with structured results including utilities and metrics
        """
        if verbose:
            print(f"\n{'='*80}")
            print(f"Running Experiment: {self.name}")
            print(f"Run ID: {self.run_id}")
            print(f"Model: {self.experiment_config.model}")
            print(f"{'='*80}\n")
        
        # Get options
        options = self.get_options()
        
        if verbose:
            print(f"Generated {len(options)} options from variables:")
            for var in self.variables:
                print(f"  {var.name} ({var.type.value}): {len(var.values)} values")
            print(f"\nExample options:")
            for opt in options[:3]:
                print(f"  - {opt['label']}")
        
        # Determine agent config key
        agent_config_key = self.experiment_config.agent_config_key
        if agent_config_key is None:
            agent_config_key = (
                "default_with_reasoning" if self.prompt_config.with_reasoning 
                else "default"
            )
        
        # Create save directory
        save_path = self.get_save_dir(base_dir=save_dir)
        os.makedirs(save_path, exist_ok=True)
        
        if verbose:
            print(f"\nSave directory: {save_path}")
            print(f"\nRunning compute_utilities...")
        
        # Run compute_utilities (which will create the graph and save example prompt)
        results = await compute_utilities(
            options=options,
            model_key=self.experiment_config.model,
            create_agent_config_path=self.experiment_config.agent_config_path,
            create_agent_config_key=agent_config_key,
            compute_utilities_config_path=self.experiment_config.utility_config_path,
            compute_utilities_config_key=self.experiment_config.utility_config_key,
            save_dir=save_path,
            save_suffix=None,
            with_reasoning=self.prompt_config.with_reasoning,
            system_message=self.prompt_config.system_prompt,
            comparison_prompt_generator=self.prompt_config.generate_prompt,
            edge_filter=self.edge_filter,
            variables=self.variables,  # Pass variables for metadata
        )
        
        if verbose:
            print(f"\n{'='*80}")
            print(f"Experiment complete!")
            print(f"Computed utilities for {len(results.utility_model.utilities)} options")
            print(f"Results saved to: {save_path}")
            print(f"{'='*80}\n")
        
        return results
